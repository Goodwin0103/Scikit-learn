{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<img src=\"Images/IMG-Wine-Quality_Banner.png\" alt=\"Title Banner\" style=\"display: block; margin-left: auto; margin-right: auto; width: 100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Wein hat Klasse, [das ist unbestritten](https://tvtropes.org/pmwiki/pmwiki.php/Main/WineIsClassy). Aber kann man die subjektive Qualität von Wein anhand seiner chemischen Eigenschaften klassifizieren? \n",
    "\n",
    "<img src=\"Images/IMG-sklearn-logo.png\" alt=\"Title Banner\" style=\"float:right; display: block; margin-left: auto; margin-right: auto; width: 30%\">\n",
    "\n",
    "Probieren wir es aus! Dazu werden wir einige Klassifikatoren und weitere Funktionen aus dem Python-Paket [```scikit-learn```](https://scikit-learn.org/stable/user_guide.html) (kurz: ```sklearn```) verwenden. ```Sklearn``` ist ein äußerst mächtiges Framework, das viele Methoden des Maschinenlernens mit einheitlichen Schnittstellen zur Verfügung stellt, so dass Sie schnell und einfach verschiedene Klassifikatoren ausprobieren können. Im Laufe dieses Notebooks werden Sie einige der Funktionenen und Objekte zur Klassifikation kennenlernen. In dem Notebook _\"Vorhersage des Alkoholgehalts von Wein\"_ werden Sie ebenfalls mit ```sklearn``` arbeiten, allerdings mit dem Fokus auf die Methoden und Objekte zur Lösung von Regressionsproblemen.\n",
    "\n",
    "Grundsätzlich gilt für beide Notebooks, dass Sie immer auch in der Dokumentation und dem User's Guide von ```sklearn``` sich weitere Informationen zu den verwendeten Objekten holen sollten, um ein tieferes Verständnis für die Zusammenhänge zu erwerben.\n",
    "\n",
    "\n",
    "## Inhalt\n",
    "<table style=\"width:256; border: 1px solid black; display: inline-block\">\n",
    "  <tr>\n",
    "    <td  style=\"text-align:right\" width=64px><img src=\"Images/IMG-csv-in.png\" style=\"float:left\"></td>\n",
    "      <td style=\"text-align:left\" width=128px>\n",
    "          <a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#import_data'>Daten importieren</a>\n",
    "      </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-magnifying-glass.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#analyze_data'>Daten analysieren</a>\n",
    "      </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-broom.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#clean_data'>Daten säubern</a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-gears.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#build_model'>Modellauswahl</a>\n",
    "        </td>\n",
    "        <tr>\n",
    "    <td style=\"text-align:right\"><img src=\"Images/IMG-new-file-out.png\" style=\"float:left\"></td>\n",
    "    <td style=\"text-align:left\" width=128px><a style=\"color:black; font-size:14px; font-weight:bold; text-decoration:none\" href='#save_model'>Modell speichern</a>\n",
    "        </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "**Hinweis:** In diesem Notebook sind einige Stellen enthalten, an denen Zufallszahlen zum Einsatz kommen (z.B. die Initialisierung des neuralen Netzes oder die Einteilung in Trainings- und Testset). Dadurch kann es passieren, dass manche Ergebnisse für Sie nicht exakt reproduzierbar sind und das relative Ranking der verschiedenen Klassifikatoren bei Ihnen etwas anders aussieht. Das ändert allerdings nichts an der generellen Vorgehensweise oder den Programmiermustern. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id='import_data'></a><div><img src=\"Images/IMG-csv-in.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">1. Daten importieren</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Die Daten der Weine wurden im Rahmen einer <a href='#data_source'>wissenschaftlichen Studie erhoben</a> und die genaue Bedeutung der einzelnen Merkmale können Sie in dem entsprechenden Paper nachlesen. Die gelisteten Merkmale sind:\n",
    "\n",
    "\n",
    "<table style=\"width:256; border: 1px solid black; display: inline-block\">\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Fixed acidity</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/nichtfluechtige-saeure/\">Nichtflüchtige Säure</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Volatile acidity:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/fluechtige-saeure/\">Flüchtige Säure</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Citric acid:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/zitronensaeure/\">Zitronensäure</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Residual sugar:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/restzucker-oder-restsuesse/\">Restzucker</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Chlorides:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Chloride</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Free sulfur dioxide:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/schwefeln/\">Freies Schwefeldioxid</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Total sulfur dioxide:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/schwefeln/\">Schwefeldioxid gesamt</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Density:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Dichte</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">pH:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\"><a href=\"https://www.wein.de/de/glossar/ph-wert/\">pH-Wert</a></p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Sulphates</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Sulfate</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Alcohol:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Alkoholgehalt</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "        <tr>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px; font-weight:bold\">Quality:</p>\n",
    "        </td>\n",
    "        <td style=\"text-align:left\"><p style=\"color:black; font-size:14px\">Zu bestimmende subjektive Qualtitätsbewertung</p>\n",
    "        </td>\n",
    "    </tr>\n",
    "    </table>   \n",
    "\n",
    "<a id='data_source'></a><b>Quelle der Daten:</b> P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "  Modeling wine preferences by data mining from physicochemical properties.\n",
    "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Uns liegen zwei Datensätze zu, von denen einer nur Rotweine und der andere nur Weißweine enthält. Für dieses Notebook wollen wir mal annehmen, dass die Farbe des Weins keinen Einfluss auf das Ergebnis hat.\n",
    "\n",
    "Die ersten Schritt sind daher der Import und die Verbindung der beiden Datensätze. Die Daten befinden sich in ```Data/winequality-red.csv``` und ```Data/winequality-white.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0               7.4              0.70         0.00             1.9      0.076   \n",
      "1               7.8              0.88         0.00             2.6      0.098   \n",
      "2               7.8              0.76         0.04             2.3      0.092   \n",
      "3              11.2              0.28         0.56             1.9      0.075   \n",
      "4               7.4              0.70         0.00             1.9      0.076   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "4893            6.2              0.21         0.29             1.6      0.039   \n",
      "4894            6.6              0.32         0.36             8.0      0.047   \n",
      "4895            6.5              0.24         0.19             1.2      0.041   \n",
      "4896            5.5              0.29         0.30             1.1      0.022   \n",
      "4897            6.0              0.21         0.38             0.8      0.020   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
      "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
      "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
      "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
      "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
      "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
      "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
      "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
      "\n",
      "      alcohol  quality  \n",
      "0         9.4        5  \n",
      "1         9.8        5  \n",
      "2         9.8        5  \n",
      "3         9.8        6  \n",
      "4         9.4        5  \n",
      "...       ...      ...  \n",
      "4893     11.2        6  \n",
      "4894      9.6        5  \n",
      "4895      9.4        6  \n",
      "4896     12.8        7  \n",
      "4897     11.8        6  \n",
      "\n",
      "[6497 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # Siehe Preprocessing/Lego-Sets/Lego Sets Preprocessing.ipynb für eine Einführung in Pandas\n",
    "\n",
    "# Datensätze importieren (pandas Funktion: pd.read_csv() Achtung: Trennzeichen ist hier das Semikolon \";\"!)\n",
    "df_red = pd.read_csv(\"Data/winequality-red.csv\", sep = ';')\n",
    "df_white = pd.read_csv(\"Data/winequality-white.csv\",  sep = ';')\n",
    "# Verbinden Sie die beiden Datensätze mit pd.concat()\n",
    "df = pd.concat([df_red, df_white], axis = 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id='analyze_data'></a><div><img src=\"Images/IMG-magnifying-glass.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\" >2. Daten analysieren</h2>\n",
    "    \n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Als nächstes wollen wir uns die Daten mal näher ansehen. Benötigen wir eine Konvertierung von Merkmalen? Müssen Werte aufgefüllt werden?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        7.215307          0.339666     0.318633        5.443235   \n",
       "std         1.296434          0.164636     0.145318        4.757804   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        3.000000   \n",
       "75%         7.700000          0.400000     0.390000        8.100000   \n",
       "max        15.900000          1.580000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.056034            30.525319            115.744574     0.994697   \n",
       "std       0.035034            17.749400             56.521855     0.002999   \n",
       "min       0.009000             1.000000              6.000000     0.987110   \n",
       "25%       0.038000            17.000000             77.000000     0.992340   \n",
       "50%       0.047000            29.000000            118.000000     0.994890   \n",
       "75%       0.065000            41.000000            156.000000     0.996990   \n",
       "max       0.611000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      3.218501     0.531268    10.491801     5.818378  \n",
       "std       0.160787     0.148806     1.192712     0.873255  \n",
       "min       2.720000     0.220000     8.000000     3.000000  \n",
       "25%       3.110000     0.430000     9.500000     5.000000  \n",
       "50%       3.210000     0.510000    10.300000     6.000000  \n",
       "75%       3.320000     0.600000    11.300000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     9.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Beginnen wir mit ein bisschen deskriptiver Statistik (pandas-Funktion describe()):\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir stellen drei wichtige Tatsachen fest:\n",
    "\n",
    "1. Es gibt insgesamt 6497 Weine gibt, für die uns Daten vorliegen (__```count```__), zumindest gibt es so viele Einträge in jeder Spalte. Wir müssen also erfreulicherweise keine Daten auffüllen! \n",
    "2. Alle Merkmale sind rein numerisch. Wir müssen also auch keine Daten konvertieren!\n",
    "3. Die Daten sind sehr unterschiedlich skaliert, da die Mittelwerte (__```mean```__) und Standardabweichungen (__```std```__) über mehrere Größenordnungen hinweg streuen.\n",
    "\n",
    "Daher bietet es sich an, die Spalten zunächst einzeln zu standardisieren, so dass sie jeweils einen Mittelwert von 0 und eine Standardabweichung von 1 haben (auch $z$-Score Normalisierung genannt). Dadurch werden also alle Merkmale in die gleiche Größenordnung gebracht, ohne die relative Verteilung zu vereinfachen.\n",
    "\n",
    "Unser Fahrplan für die Säuberung der Daten ist also klar:\n",
    "- Kein konvertieren oder auffüllen nötig\n",
    "- Standardisierung der Daten empfehlenswert\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id='clean_data'></a><div><img src=\"Images/IMG-broom.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">3. Daten säubern</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Wie bereits oben festgestellt, müssen wir keine Konvertierungen oder Ersetzungen machen, sondern nur die Standardisierung vornehmen. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Bevor wir allerdings die Standardisierung vornehmen, sollten wir zunächst die Daten in Trainings- und Testset aufteilen, damit wir nicht schon bei der Standardisierung Daten verwenden, die eigentlich vom Modell \"ungesehene\" Testdaten sein sollen. Dazu teilen wir den Datensatz zunächst in die Merkmalvektorfolge $X$ und Klassenlabel $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zunächst trennen wir den gesamten Datensatz in die Merkmale und die vorherzusagende Größe\n",
    "X = df.drop(columns = ['quality']) # Alle Spalten von df außer 'quality'\n",
    "y = df['quality'] # Nur die Spalte 'quality'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Nun kommt der eigentliche Split in Train- und Testset, den wir mit Hilfe der Funktion [```train_test_split()```](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) aus ```scikit-learn``` vornehmen wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie aus dem sklearn-Modul model_selection die Funktion train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Verwenden Sie nun die Funktion train_test_split(), um ein zurückgehaltenes (Holdout) Test-Set von 20% der gesamten Daten zu erhalten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Jetzt können wir auf dem Trainingsset die Parameter für die Standardisierung bestimmen und diese auf Trainings- und Testdaten ausführen. Wir könnten dazu natürlich von Hand in jeder Spalte den Mittelwert subtrahieren und sie durch ihre Standardabweichung teilen. Eleganter geht es jedoch mit Hilfe des Objekts [```StandardScaler```](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n"
     ]
    }
   ],
   "source": [
    "# Importieren Sie aus dem sklearn-Modul preprocessing das Objekt StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Instanziieren Sie ein Objekt StandardScaler()\n",
    "stdScaler = StandardScaler()\n",
    "# Berechnen Sie die Standardisierungsparametr auf dem Trainingsset (!) X_train mit Hilfe der Funktion \"fit()\"\n",
    "print(stdScaler.fit(X_train))\n",
    "# Wenden Sie die **selbe** Standardisierung mit Hilfe der Methode transform() auf die Trainings- und Testdaten an\n",
    "X_train = stdScaler.transform(X_train)\n",
    "X_test = stdScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Beachten Sie, dass wir keinerlei Wissen aus dem Testset in unsere Berechnungen aufgenommen haben, da der ```StandardScaler``` nur auf den Trainingsdaten parametrisiert wurde!\n",
    "\n",
    "Damit sind wir bei diesem sehr ordentlichen Datensatz schon am Ende der Datenaufbereitung und der nächste Schritt ist die Modellauswahl.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id='build_model'></a><div><img src=\"Images/IMG-gears.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">4. Modellauswahl</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Wir werden nun eine Reihe von Klassifikatoren auf den standardisierten Trainingsdaten trainieren und anhand der zurückgehaltenen Testdaten untereinander vergleichen. Um die Hyperparameter zu optimieren, dürfen wir also **nicht** die Testdaten verwenden, da Sie ja sonst schon Teil des Trainings wären. Stattdessen werden wir eine $k$-fache Kreuzvalidierung auf den Trainingsdaten durchführen, um die optimalen Hyperparameter für jeden Klassifikator zu bestimmen.\n",
    "    \n",
    "    \n",
    "Allerdings stellt sich damit schon die Frage nach der Wahl des ersten Hyperparameters: Wie groß sollen wir $k$ wählen?\n",
    "\n",
    "\n",
    "Die Antwort auf diese Frage kann uns ein Blick auf die Verteilung der Trainingslabel $y_\\mathrm{train}$ liefern. Dazu importieren wir zunächst ein Paket zur grafischen Darstellung von Daten und schauen uns dann das Histogramm der Trainingslabel an.\n",
    "\n",
    "\n",
    "Es gibt eine Vielzahl von solchen Paketen in Python, aber wir werden hier [matplotlib](https://matplotlib.org/) verwenden.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Häufigkeit')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import des Moduls zum plotten aus Matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# Dies ist ein sog. \"Magic-Kommando\", das die Darstellung der Plots direkt im Notebook ermöglicht. \n",
    "# Wenn Sie dieses vergessen, tauchen die Plots nicht auf!\n",
    "%matplotlib inline\n",
    "\n",
    "# Histogramm-Darstellung der bekannten Label im Training\n",
    "plt.hist(y_train)\n",
    "plt.xlabel(\"Qualität\")\n",
    "plt.ylabel(\"Häufigkeit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Offenbar wurden die extremen Qualitätsbeurteilungen 3 und 9 nur sehr selten ausgesprochen. Das kann unter Umständen zum Problem werden: Wenn es weniger Beobachtungen zu einem bestimmten Label gibt, als wir Folds in der $k$-fachen Kreuzvalidierung haben, dann werden einige Folds keine einzige Beobachtung mit diesem Label enthalten. Es ist daher vorteilhaft, $k$ nicht größer als die kleinste vorkommende Häufigkeit eines Labels zu wählen.\n",
    "\n",
    "Diese kleinste Häufigkeit können wir ganz einfach mit Hilfe ermitteln. Dazu verwenden wir Funktionen aus dem Paket [```numpy```](https://numpy.org/), das für numerische Berechnungen mit Matrizen in Python optimiert ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das Label 9 kommt nur 4 Mal in den Trainingsdaten vor!\n"
     ]
    }
   ],
   "source": [
    "# Import von Numpy\n",
    "import numpy as np\n",
    "\n",
    "# Bestimme die Häufigkeiten jedes vorkommenden Wertes in dem Array y_train\n",
    "labels, counts = np.unique(y_train, return_counts=True)\n",
    "# Finde die kleinste Häufigkeit\n",
    "min_counts = np.min(counts)\n",
    "# Finde das Label mit der kleinsten Häufigkeit\n",
    "rarest_label = labels[counts == min_counts]\n",
    "# Ausgabe des seltensten Labels und der entsprechenden Häufigkeit\n",
    "print(\"Das Label {} kommt nur {} Mal in den Trainingsdaten vor!\".format(*rarest_label, min_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die maximale Anzahl Folds, bei der von allen Klassen Beobachtungen in jeder Fold enthalten wären, ist also $k=4$. \n",
    "\n",
    "Mit dieser Information im Hinterkopf machen wir uns nun also daran, einige Klassifikatoren auf den Trainingsdaten auszuprobieren. \n",
    "\n",
    "Der einfachste Klassifikator in ```sklearn```, den Sie in der Vorlesung kennengelernt haben, ist der [$k$ Nächste Nachbarn Klassifikator](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importieren Sie das Objekt KNeighborsClassifier aus dem Modul neighbors im Paket sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Instanziieren Sie ein Objekt vom Type KNeighborsClassifier mit den Standardeinstellungen für alle Parameter\n",
    "knn_model = KNeighborsClassifier()\n",
    "# Trainieren (\"Fitten\") Sie das Modell\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Güte dieses Klassifikators (und auch jedes anderen Klassifikators in ```sklearn```) auf einem beliebigen Datensatz können Sie mit der Methode [```score()```](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.score) bestimmen. Bei Klassifikatoren ist die Metrik hier standardmäßig die Genauigkeit: \n",
    "\n",
    "$$\\mathrm{Genauigkeit} = \\frac{\\text{Anzahl korrekt klassifizierter Beobachtungen}}{\\text{Gesamtanzahl Beobachtungen}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard KNN - Training: 70.06 % Test: 54.38 %\n"
     ]
    }
   ],
   "source": [
    "# Trainingsgenauigkeit (in Prozent)\n",
    "train_score_knn = knn_model.score(X_train, y_train)*100\n",
    "# Testgenauigkeit (in Prozent)\n",
    "test_score_knn = knn_model.score(X_test, y_test)*100\n",
    "# Ausgabe der Performancemaße\n",
    "print(\"Standard KNN - Training: {:.2f} % Test: {:.2f} %\".format(train_score_knn, test_score_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Performance mit den Standardeinstellungen ist noch nicht besonders gut. Eine Optimierung der Hyperparameter kann dieses Ergebnis deutlich verbessern. Für diese Optimierung verwenden wir eine $k$-fache Kreuzvalidierung mit dem oben bestimmten $k=4$.\n",
    "\n",
    "Zur Optimierung der Hyperparameter (\"Tuning des Modells\") basierend auf Kreuzvalidierung bietet uns ```sklearn``` im Modul ```model_selection```(neben einigen anderen Varianten) das Objekt [```GridSearchCV```](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) an. Dieses Objekt führt eine Gittersuche (engl. _grid search_) auf einem vorgebenen Parametergitter aus und überprüft an jedem Gitterknoten die Performance des so parametrisierten Modells mit Hilfe von Kreuzvalidierung (engl. _crossvalidation_, CV). Dazu benötigt es den zu tunenden Klassifikator, das Parametergitter und weitere optionale Steuerparameter, wie die Anzahl der Folds in der Kreuzvalidierung.\n",
    "\n",
    "Die Werte der Hyperparameter, die ausprobiert werden sollen, werden in Form einer Liste von [Dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) übergeben. Jedes Dictionary enthält ein Gitter, das abgesucht wird. \n",
    "\n",
    "Am Ende wird das Modell mit dem als optimal identifizierten Hyperparametersatz auf allen Folds trainiert, so dass der Rückgabewert der Methode ```fit()``` einen auch im Sinne der Hyperparameter optimalen Klassifikator darstellt.\n",
    "\n",
    "**Es empfiehlt sich sehr, die Hyperparameteroptimierung auf einem parallen Rechner auszuführen!*** Da jede Hyperparameterkonfiguration und jede Kreuzvalidierung unabhängig voneinander berechnet werden können, ist hier ein nahezu perfekter paralleler [Speedup](https://de.wikipedia.org/wiki/Speedup) möglich. Ein einfaches Beispiel:\n",
    "\n",
    "Sie wollen prüfen, welche Zahl zwischen 1 und 10 die beste Zahl von Nachbarn in dem $k$ Nächste Nachbarn Klassifikator darstellt. Dazu müssen Sie also 10 Modelle mit 10 verschiedenen Werten für $k$ berechnen und diese miteinander vergleichen. Zum Vergleich wollen Sie jedes Modell mit 4 Folds validieren. Dazu müssen Sie also für jeden der 10 Werte von $k$ schon 4 Modell berechnen, also insgesamt 40 Trainingsvorgänge. Auf einem Single-CPU Rechner dauert dies dann zum Beispiel eine Minute. Da alle Berechnungen getrennt voneinander gemacht werden können, kann das exakt gleiche Training auf einem Parallelrechner mit z.B. 20 CPUs in 1/20 der Zeit gerechnet werden, also in diesem Beispiel in nur 3 Sekunden. Wenn noch weitere Hyperparameter optimiert oder mehr Werte ausprobiert werden sollen, explodiert der Rechenaufwand entsprechend durch die kombinatorische Vielfalt des Gitters. Parallele Ausführung ist hier also enorm wichtig. ***Wir empfehlen daher nachdrücklich das Arbeiten auf dem HPC (siehe [Einführung ins Praktikum](https://bildungsportal.sachsen.de/opal/auth/RepositoryEntry/23165501449/CourseNode/101490883666782))!***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 396 candidates, totalling 1584 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
       "                          'p': [1, 2], 'weights': ['uniform', 'distance']}],\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importieren Sie das Objekt GridSearchCV aus dem Modul model_selection im Paket sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Auswahl der zu testenden Hyperparameter (alle nicht spezifizierten bleiben auf dem Standardwert)\n",
    "param_grid_knn = [\n",
    "    {'n_neighbors': np.arange(1, 100, 1),  # Anzahl der Nachbarn; \"arange\" ist eine Numpy-Funktion zur Erzeugung einer Spanne\n",
    "     'weights': ['uniform', 'distance'], # Gewichtung der Nachbarn in Entscheidungsfindung\n",
    "     'p': [1, 2]},                       # Exponent der Abstandsfunktion (1: Manhattan; 2: Euklidisch)\n",
    "]\n",
    "\n",
    "# Instanziieren des Objekts \"GridSearchCV\"\n",
    "knn_model = GridSearchCV(KNeighborsClassifier(), # Klassifikator, der benutzt werden soll\n",
    "                         param_grid_knn,         # Hyperparametergitter\n",
    "                         cv=4,                   # Anzahl der Folds für Kreuzvalidierung\n",
    "                         verbose=10,             # Menge des Output während der Suche (größere Zahl -> mehr Info)\n",
    "                         n_jobs=-1               # Anzahl der parallel genutzen CPUs; -1: alle verfügbaren CPUs nutzen\n",
    "                        )\n",
    "\n",
    "# Trainieren Sie das Modell\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Beachten Sie in der ersten Zeile der Ausgabe der Fit-Funktion die große Anzahl von zu trainierenden Modellen (\"Fits\"), die sich aus den relativ wenigen Hyperparametern ergeben haben. \n",
    "\n",
    "Die beste gefundenen Hyperparameterkombination können Sie über die Eigenschaft ```best_params_``` der Instanz von ```GridSearchCV``` auslesen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 75, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(knn_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Zum Vergleich der Perfomance zum unoptimierten $k$ Nearest Neighbor-Klassifikator berechnen wir wieder die Genauigkeiten auf Trainings und Testset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned KNN - Training: 100.00 % Test: 66.15 %\n"
     ]
    }
   ],
   "source": [
    "train_score_knn = knn_model.score(X_train, y_train)*100\n",
    "test_score_knn = knn_model.score(X_test, y_test)*100\n",
    "print(\"Tuned KNN - Training: {:.2f} % Test: {:.2f} %\".format(train_score_knn, test_score_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Schon besser, aber vielleicht funktioniert ein anderes Modell ja noch besser? \n",
    "\n",
    "Wir vesuchen es daher mit einer Support Vector Machine zur Klassifikation. In ```sklearn``` existiert dazu das Objekt ```SVC```. Beachten Sie, dass das Programmiermuster zum Training und Test (zunächst ohne Hyperparameteroptimierung) genau das gleiche ist wie bei dem Nächste Nachbarn Klassifikator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine - Training: 60.82 % Test: 54.69 %\n"
     ]
    }
   ],
   "source": [
    "# Import des Objekts SVC aus dem Modul svm im Paket sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instanziieren eines Objekts\n",
    "svm_model = SVC(C=1)\n",
    "# Trainieren Sie das Modell\n",
    "svm_model.fit(X_train, y_train)\n",
    "# Berechnen Sie den Trainings- und Testscore in Prozent\n",
    "train_score_svm = svm_model.score(X_train, y_train)*100\n",
    "test_score_svm = svm_model.score(X_test, y_test)*100\n",
    "\n",
    "# Ausgabe der Performance\n",
    "print(\"Support Vector Machine - Training: {:.2f} % Test: {:.2f} %\".format(train_score_svm, test_score_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Die Performance der unoptimierten SVM entspricht also ungefähr der des unoptimierten KNN. Aber auch Support Vector Machines haben Hyperparameter, die Sie optimieren sollten. Insbesondere die Wahl des Kernels und des Parameters $C$ (siehe Vorlesung).\n",
    "\n",
    "**Achtung:** Die Dauer des Trainings ist stark abhängig von der Größe des Parameters $C$. Für kleine Werte von $C$ kann das Training schon nach wenigen Sekunden abgeschlossen sein, während es bei großen Werten durchaus mehrere Minuten dauern kann. Wundern Sie sich also nicht, wenn die Kreuzvalidierung zwischendurch \"eingefroren\" erscheint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    }
   ],
   "source": [
    "# Parametergitter aufstellen\n",
    "param_grid_svm = [\n",
    "    {'C': np.logspace(-5, 2, 8), # Die Numpy-Funktion \"logspace\" liefert eine logarithmische Zahlenreihe (z. B. [0.01, 0.1, 1, 10])\n",
    "     'kernel': ['linear', 'rbf']}\n",
    "]\n",
    "\n",
    "# Gittersuche aufsetzen\n",
    "svm_model = GridSearchCV(SVC(), # Klassifikator, der benutzt werden soll\n",
    "                         param_grid_svm,         # Hyperparametergitter\n",
    "                         cv=4,                   # Anzahl der Folds für Kreuzvalidierung\n",
    "                         verbose=10,             # Menge des Output während der Suche (größere Zahl -> mehr Info)\n",
    "                         n_jobs=-1               # Anzahl der parallel genutzen CPUs; -1: alle verfügbaren CPUs nutzen\n",
    "                        )\n",
    "# Gittersuche durchführen\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Geben Sie wieder die besten Parameter und die Performance auf Trainings- und Testset aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der besten gefundenen Hyperparameter\n",
    "print(svm_model.best_params_)\n",
    "# Berechnen Sie den Trainings- und Testscore in Prozent\n",
    "train_score_svm = svm_model.score(X_train, y_train)*100\n",
    "test_score_svm = svm_model.score(X_test, y_test)*100\n",
    "\n",
    "# Ausgabe der Performance\n",
    "print(\"SVM - Training: {:.2f} % Test: {:.2f} %\".format(train_score_svm, test_score_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Als letzten Klassifikator wollen wir noch ein neuronales Netz ausprobieren. ```Sklearn``` beinhaltet leider keine Methoden für Deep Learning, aber zumindest ein Mehrschichtiges Perzeptron (engl. Multi-Layer Perceptron, MLP) ist als Objekt ```MLPClassifier```vorhanden. Bei neuronalen Netzen müssen die Hyperparameter immer optimiert werden, da schon für die Anzahl der Neuronen in jeder Schicht und die Anzahl der Schichten keine sinnvollen Voreinstellungen angenommen werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des Objekts MLPClassifier aus dem Modul neural_network im Paket sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Neuronale Netze haben immer viele Hyperparameter. Hier soll nur eine kleine Auswahl untersucht werden\n",
    "param_grid_mlp = [\n",
    "    {\n",
    "        'hidden_layer_sizes': [(100, 50), (100, 100, 50), (100, 100, 100, 50)],\n",
    "        'alpha': np.logspace(-5, 1, 7),\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'early_stopping': [True, False],\n",
    "        'learning_rate': ['adaptive'],\n",
    "    }    \n",
    "]\n",
    "\n",
    "# Gittersuche aufsetzen\n",
    "mlp_model = GridSearchCV(MLPClassifier(), # Klassifikator, der benutzt werden soll\n",
    "                         param_grid_mlp,         # Hyperparametergitter\n",
    "                         cv=4,                   # Anzahl der Folds für Kreuzvalidierung\n",
    "                         verbose=10,             # Menge des Output während der Suche (größere Zahl -> mehr Info)\n",
    "                         n_jobs=-1               # Anzahl der parallel genutzen CPUs; -1: alle verfügbaren CPUs nutzen\n",
    "                        )\n",
    "# Gittersuche durchführen\n",
    "mlp_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Beachten Sie, wie viele Modelle hier trainiert werden mussten und wie lange das Training gedauert hat. Dabei waren die betrachteten Hyperparameter nur ein Teil der tatsächlich einstellbaren Größen. Auch die betrachteten Werte sind natürlich nicht alle möglichen. Es ist durchaus möglich, dass irgendwo im Hyperparameterraum eine noch besser geeignete Kombination existiert. Dieses Risiko gilt natürlich für alle Arten von Klassifikatoren, aber ganz besonders für Neuronale Netze aufgrund der großen Anzahl von Hyperparametern.\n",
    "\n",
    "Geben Sie wieder die besten Hyperparameter und Trainings- und Testperformance aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ausgabe der besten gefundenen Hyperparameter\n",
    "print(mlp_model.best_params_)\n",
    "\n",
    "# Berechnen Sie den Trainings- und Testscore in Prozent\n",
    "train_score_mlp = mlp_model.score(X_train, y_train)*100\n",
    "test_score_mlp = mlp_model.score(X_test, y_test)*100\n",
    "\n",
    "# Ausgabe der Performance\n",
    "print(\"mlp - Training: {:.2f} % Test: {:.2f} %\".format(train_score_mlp, test_score_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Um abschließend ein Modell auszuwählen, geben wir die Performance aller optimierten Klassifikatoren auf dem Testset nochmal gemeinsam aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KNN: {:.2f} %\".format(test_score_knn))\n",
    "print(\"SVM: {:.2f} %\".format(test_score_svm))\n",
    "print(\"MLP: {:.2f} %\".format(test_score_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Zunächst sieht es also so aus, als sei der $k$ Nächste Nachbarn Klassifikator der beste, aber die Performance generell schlecht. Es lohnt sich aber bei dieser speziellen Fragestellung noch einmal über die Label nachzudenken:\n",
    "\n",
    "Allgemein gilt, dass bei einer Klassifikation zwei Label keine Beziehung zueinander haben. Wenn beispielsweise Bilder von Tieren klassifiziert werden sollen, dann ist das Label \"Hund\" für ein Bild von einer Katze genauso falsch wie das Label \"Maus\". Bei manchen Fragestellungen gibt es allerdings verschiedene Arten von Fehlern, die unterschiedlich stark ins Gewicht fallen. In dem Beispiel der Klassifikation von Tierbildern könnte man postulieren, dass das Label \"Hund\" für eine Katze zwar falsch, aber doch besser als das Label \"Dinosaurier\" ist, weil es sich zumindest um ein nicht-ausgestorbenes Säugetier handelt, das viele Eigenschaften (Fell, vier Beine, Schwanz, Haustier) einer Katze teilt. Je nach Anwendung kann das also trotzdem noch ein akzeptables Ergebnis sein.\n",
    "\n",
    "In unserem Beispiel hier existiert auch eine Beziehung zwischen den Labeln: Einen Wein als \"4\" zu klassifizieren, obwohl er tatsächlich mit einer 8 bewertet wurde, ist offensichtlich schlechter, als den selben Wein als \"7\" zu klassifizieren. Die bisher durchgängig verwendete Metrik für das Scoring kennt aber nur \"genau getroffen\" oder \"falsch\", ohne Stufen dazwischen.\n",
    "\n",
    "Wir können aber selbst eine neue Metrik definieren, indem wir sagen, dass eine Abweichung vom tatsächlichen Wert von $\\pm$1 in der Klassifizierung noch als korrekt zählt. Dafür müssen wir die folgenden Schritte für jeden Klassifikator implementieren:\n",
    "\n",
    "1. Vorhersage der Qualitätsstufe\n",
    "2. Absolute Differenz zur tatsächlichen Qualitätsstufe bilden\n",
    "3. Verhältnis aus Anzahl der Vorhersagen mit einer Abweichung von $\\leq 1$ zu Gesamtanzahl der Vorhersagen berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen des KNN\n",
    "y_predicted = knn_model.predict(X_test)\n",
    "# Berechnung der \"eins-daneben-Performance\"\n",
    "one_off_knn = np.sum(np.abs(y_predicted-y_test) <= 1 ) / len(y_predicted) * 100\n",
    "# Ausgabe\n",
    "print(\"KNN one-off accuracy: Test {:.2f}\".format(one_off_knn))\n",
    "\n",
    "# Vorhersagen der SVM\n",
    "y_predicted = svm_model.predict(X_test)\n",
    "# Berechnung der \"eins-daneben-Performance\"\n",
    "one_off_svm = np.sum(np.abs(y_predicted-y_test) <= 1 ) / len(y_predicted) * 100\n",
    "# Ausgabe\n",
    "print(\"SVM one-off accuracy: Test {:.2f}\".format(one_off_svm))\n",
    "\n",
    "# Vorhersagen des MLP\n",
    "y_predicted = mlp_model.predict(X_test)\n",
    "# Berechnung der \"eins-daneben-Performance\"\n",
    "one_off_mlp = np.sum(np.abs(y_predicted-y_test) <= 1 ) / len(y_predicted) * 100\n",
    "# Ausgabe\n",
    "print(\"MLP one-off accuracy: Test {:.2f}\".format(one_off_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wir stellen fest, dass das Ranking der Klassifikatoren sich etwas verändert hat: Zwar ist der Nächste Nachbarn-Klassifikator noch immer der beste, aber das MLP ist nun leicht hinter der SVM gelandet. Die falschen Vorhersagen des MLP liegen also offenbar öfter weiter daneben, als die der SVM.\n",
    "\n",
    "**Wichtig:** Wir haben bei dieser Vorgehensweise nun ganz am Ende unser Gütekriterium verändert. Sinnvoller wäre es, bereits im Training die \"One-Off Accuracy\" zur Bewertung der Modell zu verwenden. Dazu müssten Sie nur eine Funktion ```one_off_accuracy(model, X, y)``` definieren, und diese bei der Instanziierung des ```GridSearchCV```-Objekts im Parameter ```scoring``` übergeben. Funktionen sind in Python ganz normale Objekte und können daher genau wie jedes andere Objekt einfach durch ihren Namen übergeben werden. Probieren Sie es doch einfach mal aus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition unserer angepassten Metrik (\"Scoring-Funktion\")\n",
    "def one_off_accuracy(model, X, y):\n",
    "    # Vorhersage des Modells anhand der Daten X machen\n",
    "    y_predicted =  model.predict(X)\n",
    "    # Berechnung der \"eins-daneben-Performance\"\n",
    "    one_off = np.sum(np.abs(y_predicted-y) <= 1 ) / len(y_predicted) * 100\n",
    "    \n",
    "    # Rückgabe des errechneten Werts\n",
    "    return one_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gittersuche erneut aufsetzen (gleiches Parametergitter wie oben, nur andere Scoring-Funktion)\n",
    "knn_model = GridSearchCV(KNeighborsClassifier(), \n",
    "                         param_grid_knn, \n",
    "                         scoring='accuracy', cv=4, verbose=10, n_jobs=-1)\n",
    "\n",
    "# Gittersuche durchführen\n",
    "knn_model.fit(X_train, y_train)\n",
    "# Ausgabe der Performance\n",
    "print(\"Tuned KNN: {:.2f} %\".format(one_off_accuracy(knn_model, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gittersuche erneut aufsetzen (gleiches Parametergitter wie oben, nur andere Scoring-Funktion)\n",
    "svm_model = GridSearchCV(SVC(), # Klassifikator, der benutzt werden soll\n",
    "                         param_grid_svm,# Hyperparametergitter\n",
    "                         scoring = 'balanced_accuracy',\n",
    "                         cv=4,                   # Anzahl der Folds für Kreuzvalidierung\n",
    "                         verbose=10,             # Menge des Output während der Suche (größere Zahl -> mehr Info)\n",
    "                         n_jobs=-1               # Anzahl der parallel genutzen CPUs; -1: alle verfügbaren CPUs nutzen\n",
    "                        )\n",
    "\n",
    "# Gittersuche durchführen\n",
    "svm_model.fit(X_train, y_train)\n",
    "# Ausgabe der Performance\n",
    "print(\"Tuned SVM: {:.2f} %\".format(one_off_accuracy(svm_model, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gittersuche erneut aufsetzen (gleiches Parametergitter wie oben, nur andere Scoring-Funktion)\n",
    "mlp_model =  GridSearchCV(MLPClassifier(), # Klassifikator, der benutzt werden soll\n",
    "                         param_grid_mlp,# Hyperparametergitter\n",
    "                         scoring = 'average_precision',\n",
    "                         cv=4,                   # Anzahl der Folds für Kreuzvalidierung\n",
    "                         verbose=10,             # Menge des Output während der Suche (größere Zahl -> mehr Info)\n",
    "                         n_jobs=-1               # Anzahl der parallel genutzen CPUs; -1: alle verfügbaren CPUs nutzen\n",
    "                        )\n",
    "\n",
    "# Gittersuche durchführen\n",
    "mlp_model.fit(X_train, y_train)\n",
    "# Ausgabe der Performance\n",
    "print(\"Tuned MLP: {:.2f} %\".format(one_off_accuracy(mlp_model, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Offenbar hat das Training mit der neuen Metrik die Performance auf den Testdaten noch ein kleines Stück verbessert, was wir auch erwarten würden, da nun im Training und im Test der gleiche Maßstab (bzw. die gleiche Metrik) angelegt wurde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "<a id='save_model'></a><div><img src=\"Images/IMG-new-file-out.png\" style=\"float:left\"> <h2 style=\"position: relative; top: 6px; left:5px\">5. Modell speichern</h2>\n",
    "<p style=\"position: relative; top: 10px\">\n",
    "Auch mit der neuen Metrik ist der KNN-Klassifikator noch der beste. Allerdings ist die Performance so nah an der SVM, dass der Unterschied kaum ins Gewicht fallen würde. Weil KNN-Klassifikatoren relativ langsam sind, da ja für jedes Beispiel aus dem Trainingsset die Ähnlichkeit berechnet werden muss, kann der minimale Performanceverlust der SVM je nach Anwendungsanforderungen durch die Geschwindigkeit der Vorhersage womöglich ausgeglichen werden. </p>\n",
    "\n",
    "Wir speichern daher beide Modelle ab. Hierzu importieren wir das Modul ```pickle```und schreiben die Modelle und (ganz wichtig) auch das Objekt zur Standardisierung in eine Binärdatei. Wenn wir den Standardisierer nicht auch speicher würden, könnte ein Anwender unseres Modells neue Daten nicht standardisieren und so keine sinnvollen Vorhersagen machen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren Sie das Modul pickle\n",
    "import pickle\n",
    "\n",
    "with open('wine_quality_model.pickle', 'wb') as model_file:\n",
    "    # Schreiben Sie die drei Objekte in die Datei\n",
    "    pickle.dump([knn_model, svm_model, stdScaler], model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Wenn Sie die Modelle an anderer Stelle wieder benutzen möchten, können Sie sie direkt aus der Binärdatei laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wine_quality_model.pickle', 'rb') as model_file:\n",
    "    # Entpacken Sie die Objekte aus der Datei in drei neue Variablen\n",
    "    knn, svm, scaler = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Das war's!\n",
    "\n",
    "<img src=\"Images/IMG-cheers.gif\" alt=\"Footer\" style=\"display: block; margin-left: auto; margin-right: auto; width: 100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "<div>Wine data from <a href=\"http://archive.ics.uci.edu/ml/datasets/Wine\">UCI Machine Learning Repository</a></div>\n",
    "<div>Footer via <a href=\"https://media.giphy.com/media/BNjLM5WNcVyM0/giphy.gif\">Giphy</a></div>\n",
    "<div>Icons made by <a href=\"https://www.flaticon.com/authors/swifticons\" title=\"Swifticons\">Swifticons</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a></div>\n",
    "<div>Notebook erstellt von Yifei Li und <a href=\"mailto:simon.stone@tu-dresden.de?Subject=Frage%20zu%20Jupyter%20Notebook%20Titanic\" target=\"_top\">Simon Stone</a></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
